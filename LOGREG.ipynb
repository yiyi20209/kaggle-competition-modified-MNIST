{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-04T22:20:44.461556Z",
     "iopub.status.busy": "2022-11-04T22:20:44.460678Z",
     "iopub.status.idle": "2022-11-04T22:21:14.430252Z",
     "shell.execute_reply": "2022-11-04T22:21:14.429196Z",
     "shell.execute_reply.started": "2022-11-04T22:20:44.461450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/classification-of-mnist-digits/train_result.csv\n",
      "/kaggle/input/classification-of-mnist-digits/train.csv\n",
      "/kaggle/input/classification-of-mnist-digits/test.csv\n"
     ]
    }
   ],
   "source": [
    "#MNIST pair of digits recognition using Softmax regression from scratch\n",
    "#Yi Cong Li (20122756)\n",
    "#this code is built using inpirations from Lab 1,2,3 and my existing project for Kaggle competition Weather-detect last year\n",
    "#please make sure to run this code in default kaggle notebook environnment of competition\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt # plot for result analysis\n",
    "import time # time the process\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "#helper functions\n",
    "\n",
    "#function calculating confusion matrix\n",
    "def conf_matrix(y_test, y_pred):\n",
    "\n",
    "    n_classes = int(max(y_test))\n",
    "    matrix = np.zeros((n_classes,n_classes))\n",
    "\n",
    "    for (test, pred) in zip(y_test, y_pred):\n",
    "        matrix[test-1, pred-1] += 1\n",
    "\n",
    "    return matrix\n",
    "\n",
    "#function returning softmax of x\n",
    "def softmax(x):\n",
    "\n",
    "    e = np.exp(x- np.max(x, axis=1, keepdims=True)) # minus the maximum for numerical stability\n",
    "\n",
    "    return e / np.sum(e, axis=1, keepdims=True)\n",
    "\n",
    "#function returning onehot encodage of y\n",
    "def one_hot(y):\n",
    "    \n",
    "    l = len(y)\n",
    "    y_hot = np.zeros((l, len(np.unique(y))))\n",
    "    \n",
    "    y_hot[np.arange(l), y] = 1\n",
    "    \n",
    "    return y_hot\n",
    "\n",
    "#function calculating accuracy (similarity between labels and predictions)\n",
    "def compute_accuracy(y_test, pred):\n",
    "    return np.sum(y_test == pred) / len(y_test)\n",
    "\n",
    "\n",
    "#loading train/val data\n",
    "train_data_path = '/kaggle/input/classification-of-mnist-digits/train.csv'\n",
    "df = pd.read_csv(train_data_path)\n",
    "#drop the useless feature\n",
    "df = df.drop(['Unnamed: 1568'], axis = 1)\n",
    "X_data = df.values.astype(np.float32)\n",
    "\n",
    "\n",
    "#loading test data\n",
    "test_data_path = '/kaggle/input/classification-of-mnist-digits/test.csv'\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "#drop the useless feature\n",
    "df_test = df_test.drop(['Unnamed: 1568'], axis = 1)\n",
    "X_test = df_test.values.astype(np.float32)\n",
    "\n",
    "#loading train/val labels\n",
    "train_labels_path = '/kaggle/input/classification-of-mnist-digits/train_result.csv'\n",
    "df_train_labels = pd.read_csv(train_labels_path)\n",
    "y_data = df_train_labels['Class'].to_numpy()\n",
    "\n",
    "#split train set and validation set randomly using seed 6390, 80% train, 20% validation\n",
    "np.random.seed(6390)\n",
    "len_train = round(0.80*X_data.shape[0])\n",
    "idx = np.arange(X_data.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "#train set\n",
    "train_idx = idx[:len_train]\n",
    "X_train = X_data[train_idx] \n",
    "y_train = y_data[train_idx]\n",
    "\n",
    "#validation set\n",
    "val_idx = idx[len_train:]\n",
    "X_val = X_data[val_idx]\n",
    "y_val = y_data[val_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T22:21:14.432588Z",
     "iopub.status.busy": "2022-11-04T22:21:14.431808Z",
     "iopub.status.idle": "2022-11-04T22:21:14.440708Z",
     "shell.execute_reply": "2022-11-04T22:21:14.440002Z",
     "shell.execute_reply.started": "2022-11-04T22:21:14.432551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Oversampling trainset\\ndf_train_X = pd.DataFrame(X_train)\\ndf_train_y = pd.DataFrame(y_train)\\n\\ndf_train_data = df_train_X.copy()\\ndf_train_data['class'] = df_train_y\\nfreq_list = df_train_data['class'].value_counts()\\nnb_max_samples = freq_list.max()\\nfor i in range(19):\\n    subset = df_train_data[df_train_data['class'] == i].copy()\\n    ratio = np.floor(nb_max_samples / freq_list[i]).astype('int')\\n    if ratio > 1:\\n        df_train_data = df_train_data.append([subset]*(ratio-1),ignore_index=True)\\n    subset = df_train_data[df_train_data['class'] == i].copy()\\n    diff = nb_max_samples - subset.shape[0]\\n    df_train_data = df_train_data.append(subset.iloc[:diff,:])\\ndf_train_data = df_train_data.sample(frac=1)\\ndf_X_train = df_train_data.copy().drop(['class'], axis = 1)\\nX_train = df_X_train.to_numpy()\\ndf_y_train = df_train_data.copy()['class']\\ny_train = df_y_train.to_numpy()\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Oversampling trainset\n",
    "df_train_X = pd.DataFrame(X_train)\n",
    "df_train_y = pd.DataFrame(y_train)\n",
    "\n",
    "df_train_data = df_train_X.copy()\n",
    "df_train_data['class'] = df_train_y\n",
    "freq_list = df_train_data['class'].value_counts()\n",
    "nb_max_samples = freq_list.max()\n",
    "for i in range(19):\n",
    "    subset = df_train_data[df_train_data['class'] == i].copy()\n",
    "    ratio = np.floor(nb_max_samples / freq_list[i]).astype('int')\n",
    "    if ratio > 1:\n",
    "        df_train_data = df_train_data.append([subset]*(ratio-1),ignore_index=True)\n",
    "    subset = df_train_data[df_train_data['class'] == i].copy()\n",
    "    diff = nb_max_samples - subset.shape[0]\n",
    "    df_train_data = df_train_data.append(subset.iloc[:diff,:])\n",
    "df_train_data = df_train_data.sample(frac=1)\n",
    "df_X_train = df_train_data.copy().drop(['class'], axis = 1)\n",
    "X_train = df_X_train.to_numpy()\n",
    "df_y_train = df_train_data.copy()['class']\n",
    "y_train = df_y_train.to_numpy()\n",
    "\"\"\"\n",
    "#Code above is for oversampling from scratch, however the model performed worse after this naive oversampling, probably that\n",
    "#Softmax weight matrix overfitting some of the oversampled data, since they are simply duplications. Therefore, this part removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T22:21:14.442582Z",
     "iopub.status.busy": "2022-11-04T22:21:14.441786Z",
     "iopub.status.idle": "2022-11-05T00:24:45.636390Z",
     "shell.execute_reply": "2022-11-05T00:24:45.634972Z",
     "shell.execute_reply.started": "2022-11-04T22:21:14.442551Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss = 2.9748336633637775, accuracy = 0.0524, accuracy_val = 0.0913\n",
      "epoch 100, loss = 2.481951278648489, accuracy = 0.1812, accuracy_val = 0.1675\n",
      "epoch 200, loss = 2.387711542188063, accuracy = 0.207325, accuracy_val = 0.1872\n",
      "epoch 300, loss = 2.3374084302481175, accuracy = 0.21815, accuracy_val = 0.1916\n",
      "epoch 400, loss = 2.3045082318509915, accuracy = 0.225175, accuracy_val = 0.1949\n",
      "epoch 500, loss = 2.2806609384375345, accuracy = 0.230025, accuracy_val = 0.1969\n",
      "epoch 600, loss = 2.2622384649429286, accuracy = 0.234375, accuracy_val = 0.1996\n",
      "epoch 700, loss = 2.247376181357362, accuracy = 0.237525, accuracy_val = 0.2012\n",
      "epoch 800, loss = 2.235005484105873, accuracy = 0.2402, accuracy_val = 0.2029\n",
      "epoch 900, loss = 2.224464005576953, accuracy = 0.2435, accuracy_val = 0.2035\n",
      "epoch 1000, loss = 2.2153160094432156, accuracy = 0.246025, accuracy_val = 0.2039\n",
      "epoch 1100, loss = 2.2072611522446435, accuracy = 0.248375, accuracy_val = 0.2052\n",
      "epoch 1200, loss = 2.200084494759923, accuracy = 0.2508, accuracy_val = 0.206\n",
      "epoch 1300, loss = 2.1936274023902764, accuracy = 0.25295, accuracy_val = 0.2059\n",
      "epoch 1400, loss = 2.187769742894357, accuracy = 0.25535, accuracy_val = 0.2067\n",
      "epoch 1500, loss = 2.182418535041528, accuracy = 0.257, accuracy_val = 0.207\n",
      "epoch 1600, loss = 2.1775004525379353, accuracy = 0.2583, accuracy_val = 0.2063\n",
      "epoch 1700, loss = 2.1729567229974003, accuracy = 0.2596, accuracy_val = 0.2068\n",
      "epoch 1800, loss = 2.1687395652380896, accuracy = 0.2603, accuracy_val = 0.207\n",
      "epoch 1900, loss = 2.1648096436991087, accuracy = 0.262, accuracy_val = 0.208\n",
      "epoch 2000, loss = 2.1611342126979016, accuracy = 0.2628, accuracy_val = 0.2084\n",
      "epoch 2100, loss = 2.1576857392196014, accuracy = 0.264, accuracy_val = 0.2078\n",
      "epoch 2200, loss = 2.1544408643938504, accuracy = 0.264825, accuracy_val = 0.208\n",
      "epoch 2300, loss = 2.15137960904346, accuracy = 0.26585, accuracy_val = 0.208\n",
      "epoch 2400, loss = 2.1484847580056554, accuracy = 0.266975, accuracy_val = 0.2075\n",
      "epoch 2500, loss = 2.1457413773421283, accuracy = 0.268275, accuracy_val = 0.2076\n",
      "epoch 2600, loss = 2.1431364316656256, accuracy = 0.26915, accuracy_val = 0.2073\n",
      "epoch 2700, loss = 2.1406584778238598, accuracy = 0.269675, accuracy_val = 0.2079\n",
      "epoch 2800, loss = 2.1382974174786966, accuracy = 0.26975, accuracy_val = 0.2077\n",
      "epoch 2900, loss = 2.1360442955845085, accuracy = 0.270675, accuracy_val = 0.2073\n",
      "epoch 3000, loss = 2.1338911349805803, accuracy = 0.27115, accuracy_val = 0.2078\n",
      "epoch 3100, loss = 2.1318307996507886, accuracy = 0.271975, accuracy_val = 0.2091\n",
      "epoch 3200, loss = 2.1298568809267526, accuracy = 0.272325, accuracy_val = 0.2089\n",
      "epoch 3300, loss = 2.1279636021942334, accuracy = 0.273275, accuracy_val = 0.2088\n",
      "epoch 3400, loss = 2.12614573862855, accuracy = 0.274125, accuracy_val = 0.2087\n",
      "epoch 3500, loss = 2.1243985492187396, accuracy = 0.274975, accuracy_val = 0.2094\n",
      "epoch 3600, loss = 2.1227177189028343, accuracy = 0.2756, accuracy_val = 0.2094\n",
      "epoch 3700, loss = 2.1210993090714885, accuracy = 0.2763, accuracy_val = 0.2095\n",
      "epoch 3800, loss = 2.1195397150360433, accuracy = 0.2768, accuracy_val = 0.2099\n",
      "epoch 3900, loss = 2.1180356293229465, accuracy = 0.277175, accuracy_val = 0.2105\n",
      "epoch 4000, loss = 2.1165840098665756, accuracy = 0.27795, accuracy_val = 0.2106\n",
      "epoch 4100, loss = 2.1151820523396165, accuracy = 0.27835, accuracy_val = 0.2105\n",
      "epoch 4200, loss = 2.113827165993868, accuracy = 0.278725, accuracy_val = 0.2108\n",
      "epoch 4300, loss = 2.1125169524920175, accuracy = 0.2794, accuracy_val = 0.211\n",
      "epoch 4400, loss = 2.1112491872980237, accuracy = 0.279925, accuracy_val = 0.2114\n",
      "epoch 4500, loss = 2.1100218032646914, accuracy = 0.280325, accuracy_val = 0.2115\n",
      "epoch 4600, loss = 2.1088328761149326, accuracy = 0.280875, accuracy_val = 0.2113\n",
      "epoch 4700, loss = 2.1076806115608853, accuracy = 0.28125, accuracy_val = 0.2113\n",
      "epoch 4800, loss = 2.1065633338443486, accuracy = 0.281825, accuracy_val = 0.2108\n",
      "epoch 4900, loss = 2.105479475514565, accuracy = 0.28235, accuracy_val = 0.2108\n",
      "epoch 5000, loss = 2.10442756828653, accuracy = 0.282725, accuracy_val = 0.2108\n",
      "epoch 5100, loss = 2.103406234845637, accuracy = 0.283, accuracy_val = 0.211\n",
      "epoch 5200, loss = 2.1024141814834896, accuracy = 0.283325, accuracy_val = 0.2111\n",
      "epoch 5300, loss = 2.1014501914657164, accuracy = 0.28405, accuracy_val = 0.2115\n",
      "epoch 5400, loss = 2.100513119046124, accuracy = 0.28445, accuracy_val = 0.2119\n",
      "epoch 5500, loss = 2.0996018840530066, accuracy = 0.285, accuracy_val = 0.2119\n",
      "epoch 5600, loss = 2.098715466983143, accuracy = 0.2853, accuracy_val = 0.2119\n",
      "epoch 5700, loss = 2.0978529045473433, accuracy = 0.285575, accuracy_val = 0.2121\n",
      "epoch 5800, loss = 2.0970132856185204, accuracy = 0.286075, accuracy_val = 0.2117\n",
      "epoch 5900, loss = 2.096195747539347, accuracy = 0.286375, accuracy_val = 0.2116\n",
      "epoch 6000, loss = 2.095399472751804, accuracy = 0.286525, accuracy_val = 0.2116\n",
      "epoch 6100, loss = 2.0946236857155043, accuracy = 0.2867, accuracy_val = 0.2116\n",
      "epoch 6200, loss = 2.0938676500855093, accuracy = 0.287075, accuracy_val = 0.212\n",
      "epoch 6300, loss = 2.0931306661238427, accuracy = 0.2874, accuracy_val = 0.2117\n",
      "epoch 6400, loss = 2.0924120683217997, accuracy = 0.2875, accuracy_val = 0.2116\n",
      "epoch 6500, loss = 2.091711223212747, accuracy = 0.287925, accuracy_val = 0.2119\n",
      "epoch 6600, loss = 2.091027527357355, accuracy = 0.28825, accuracy_val = 0.2118\n",
      "epoch 6700, loss = 2.090360405485177, accuracy = 0.288475, accuracy_val = 0.2118\n",
      "epoch 6800, loss = 2.089709308778204, accuracy = 0.288725, accuracy_val = 0.2117\n",
      "epoch 6900, loss = 2.089073713283555, accuracy = 0.288925, accuracy_val = 0.2121\n",
      "epoch 7000, loss = 2.0884531184437902, accuracy = 0.2893, accuracy_val = 0.2117\n",
      "epoch 7100, loss = 2.08784704573453, accuracy = 0.289525, accuracy_val = 0.2116\n",
      "epoch 7200, loss = 2.087255037400082, accuracy = 0.2896, accuracy_val = 0.212\n",
      "epoch 7300, loss = 2.086676655278729, accuracy = 0.28995, accuracy_val = 0.2119\n",
      "epoch 7400, loss = 2.086111479710131, accuracy = 0.290125, accuracy_val = 0.2116\n",
      "epoch 7500, loss = 2.0855591085180456, accuracy = 0.29025, accuracy_val = 0.2118\n",
      "epoch 7600, loss = 2.0850191560621973, accuracy = 0.2904, accuracy_val = 0.2118\n",
      "epoch 7700, loss = 2.084491252353728, accuracy = 0.290325, accuracy_val = 0.2118\n",
      "epoch 7800, loss = 2.08397504222916, accuracy = 0.290375, accuracy_val = 0.2119\n",
      "epoch 7900, loss = 2.083470184578292, accuracy = 0.290675, accuracy_val = 0.212\n",
      "epoch 8000, loss = 2.0829763516218316, accuracy = 0.29095, accuracy_val = 0.2122\n",
      "epoch 8100, loss = 2.0824932282349717, accuracy = 0.2912, accuracy_val = 0.2119\n",
      "epoch 8200, loss = 2.082020511313438, accuracy = 0.2915, accuracy_val = 0.2123\n",
      "epoch 8300, loss = 2.0815579091788354, accuracy = 0.291625, accuracy_val = 0.2128\n",
      "epoch 8400, loss = 2.0811051410204082, accuracy = 0.2918, accuracy_val = 0.2128\n",
      "epoch 8500, loss = 2.080661936370554, accuracy = 0.292125, accuracy_val = 0.2131\n",
      " best accuracy_val =  0.2133  epochs of first occurence of this accuracy_val =  8584  time used =  2.058097084098392hour\n",
      "confusion matrix is:\n",
      "[[110.  34.  13.   5.   3.   7.   8.   5.   1.   3.   0.   0.   0.   0.\n",
      "    0.   0.   0.   1.]\n",
      " [ 48. 117.  68.  26.   9.   7.  22.   9.   4.   3.   0.   0.   0.   1.\n",
      "    0.   0.   0.   5.]\n",
      " [  8.  89. 155.  67.  27.  21.  23.  24.  14.  17.   3.   3.   0.   0.\n",
      "    0.   1.   0.   3.]\n",
      " [  6.  17. 100.  89.  62.  30.  36.  48.  52.  26.  10.   7.   9.   2.\n",
      "    3.   1.   0.   2.]\n",
      " [ 12.   7.  60.  75.  78.  60.  51.  63.  43. 106.  20.   6.   6.   4.\n",
      "    3.   0.   2.  17.]\n",
      " [ 14.  19.  22.  53. 101. 107.  99.  58.  58.  88.  52.  18.   9.   4.\n",
      "    8.   2.   2.  11.]\n",
      " [ 13.  22.  17.  46.  59.  76. 121.  90.  89.  87.  56.  48.   9.  16.\n",
      "    4.   4.   1.  18.]\n",
      " [ 10.  21.  32.  24.  67. 114.  92. 156. 118. 153.  51.  49.  40.  14.\n",
      "    9.  12.   3.   0.]\n",
      " [  7.  19.  16.  25.  40.  58.  82. 105. 189. 146.  78.  87.  53.  20.\n",
      "   22.  14.  13.   4.]\n",
      " [  2.   9.   7.  29.  21.  30.  49.  86. 122. 224.  95.  96.  77.  10.\n",
      "   15.  23.  16.   3.]\n",
      " [  2.   0.   6.  18.  16.  27.  31.  56.  80. 134. 111.  69. 103.  52.\n",
      "   19.  31.  13.   3.]\n",
      " [  0.   0.   1.   8.   9.  14.  41.  27.  58.  96.  80. 109.  77.  69.\n",
      "   29.  27.  24.   3.]\n",
      " [  0.   0.   1.   0.  11.   3.  35.  38.  24.  43.  44.  65. 120.  80.\n",
      "   63.  15.  17.  36.]\n",
      " [  0.   0.   0.   1.   0.  16.  10.  26.  48.  40.  37.  56.  52.  49.\n",
      "   42.  66.   5.   3.]\n",
      " [  1.   1.   0.   0.   0.   5.  12.  14.  22.  38.  25.  27.  51.  41.\n",
      "   83.  75.   8.   0.]\n",
      " [  0.   0.   1.   1.   0.   1.   2.   9.   7.  23.  13.  13.  26.  15.\n",
      "   15. 125.  30.  14.]\n",
      " [  0.   0.   0.   1.   1.   0.   0.   2.  14.  12.  13.  17.  13.   4.\n",
      "   13.  37.  49.   1.]\n",
      " [ 14.   1.   0.   0.   0.   0.   1.   4.   3.   1.   0.   1.   8.   1.\n",
      "    3.  20.   3. 141.]]\n",
      "Result accuracy_val =  0.2133\n",
      "Result accuracy_train =  0.2923\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model of softmax regression\n",
    "class SoftmaxRegression():\n",
    "    \n",
    "    #initialize with number of epochs, learning rate and L2 regularizer coefficient\n",
    "    #parameters are initialized with values determined by exhaustive trials (naive hyperparameter tunning)\n",
    "    def __init__(self, epochs=8585, lr=0.1, reg = 1e-4):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "\n",
    "    #train model with X, y of train set, use X_val, y_val to chose near best parameters according to validation accuracy\n",
    "    def train(self, X, y, X_val, y_val):\n",
    "        \n",
    "        #lists to store accuracies and losses\n",
    "        accuracies = []\n",
    "        accuracies_val = []\n",
    "        losses = []\n",
    "        \n",
    "        #augment bias parameter to X\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        X_val = np.insert(X_val, 0, 1, axis=1)\n",
    "\n",
    "        #glorot initialization for theta\n",
    "        limit = np.sqrt(2 / X.shape[1])\n",
    "        np.random.seed(6395)\n",
    "        self.theta = np.random.uniform(-limit, limit, (X.shape[1], len(np.unique(y))))\n",
    "\n",
    "        start = time.time()\n",
    "        #batch gradient descent with epochs\n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            #softmax to predict the probabilities of each data point to belong to each class\n",
    "            y_preds = softmax(X.dot(self.theta))\n",
    "            #loss function (cross entropy) with L2 regularization (squared theta)\n",
    "            loss = -np.mean(np.log(y_preds[np.arange(len(y)), y])) + self.reg*1/(len(y))*np.sum(self.theta**2)\n",
    "            gradient = (1/X.shape[0])*X.T.dot(y_preds - one_hot(y))\n",
    "            # Update theta with L2 regularizer\n",
    "            self.theta -= self.lr * gradient + self.reg*self.theta\n",
    "            \n",
    "            #predictions on train set\n",
    "            preds = np.argmax(y_preds, axis=1)\n",
    "            \n",
    "            #predictions on validation set\n",
    "            y_preds_val = softmax(X_val.dot(self.theta))\n",
    "            preds_val = np.argmax(y_preds_val, axis=1)\n",
    "            \n",
    "            #accuracy of train prediction and validation prediction\n",
    "            accuracy = compute_accuracy(y, preds)\n",
    "            accuracy_val = compute_accuracy(y_val, preds_val)\n",
    "            \n",
    "            #information printed to observe if loss and error decrease during the process\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            accuracies_val.append(accuracy_val)\n",
    "            if epoch % 100 == 0:\n",
    "                print('epoch {epoch}, loss = {loss}, accuracy = {accuracy}, accuracy_val = {accuracy_val}'\n",
    "                      .format(epoch=epoch, loss=loss, accuracy=accuracy, accuracy_val=accuracy_val))\n",
    "        end = time.time()\n",
    "\n",
    "        #information printed for best epochs (highest validation accuracy) within the epochs choosen \n",
    "        print(' best accuracy_val = ', \n",
    "              np.max(accuracies_val), \n",
    "              ' epochs of first occurence of this accuracy_val = ', \n",
    "              np.argmax(accuracies_val),\n",
    "              ' time used = ', str((end - start)/60/60) + 'hour')\n",
    "        len_epochs = np.arange(self.epochs)\n",
    "        \n",
    "        plt.figure(figsize= (8,6),dpi=80)\n",
    "        plt.title('Epoch-Accuracy and Loss Graph')\n",
    "        plt.plot(len_epochs, losses, label = \"loss\")\n",
    "        plt.plot(len_epochs, accuracies, label = \"train accuracy\")\n",
    "        plt.plot(len_epochs, accuracies_val, label = \"validation accuracy\")\n",
    "        plt.xlabel(\"number of epochs\")\n",
    "        plt.legend()\n",
    "        plt.show\n",
    "        return self\n",
    "\n",
    "    #make prediction\n",
    "    def predict(self, X):\n",
    "        \n",
    "        #augment bias.\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "        #predicted probabilities (sum to 1) for each sample to belong to each class\n",
    "        y_preds = softmax(X.dot(self.theta))\n",
    "\n",
    "        #return class of highest probability\n",
    "        return np.argmax(y_preds, axis=1)\n",
    "\n",
    "\n",
    "#train model and predict test set.\n",
    "model = SoftmaxRegression()\n",
    "model.train(X_train, y_train, X_val, y_val)\n",
    "preds_val = model.predict(X_val)\n",
    "preds_train = model.predict(X_train)\n",
    "#compute accuracy rates of predictions.\n",
    "accuracy_rate_val = compute_accuracy(y_val, preds_val)\n",
    "accuracy_rate_train = compute_accuracy(y_train, preds_train)\n",
    "    \n",
    "confmat = conf_matrix(y_val, preds_val)\n",
    "    \n",
    "print('confusion matrix is:')\n",
    "print(confmat)\n",
    "    \n",
    "preds_result = model.predict(X_test)\n",
    "print('Result accuracy_val = ',accuracy_rate_val)\n",
    "print('Result accuracy_train = ',accuracy_rate_train)\n",
    "    \n",
    "\n",
    "output = pd.DataFrame({'Index': np.arange(X_test.shape[0]), 'Class': preds_result})\n",
    "output.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
